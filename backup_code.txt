import os
import cv2
import torch
import time
from datetime import datetime
from autoTransform.transform import process_auto_transform
from splitImage.split import process_split_image
from readLicense.read import process_read_license

import warnings
warnings.filterwarnings("ignore")

def main():
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(current_dir, "readLicense", "EfficientNet_model.pth")
        yolo_model_path = os.path.join(current_dir, "detectCar", "yolov5", "best_4.pt")
        font_path = '/Users/gift/Workspace/OCR/Final/AnantasonReno-SemiExpanded-Italic.otf'

        # สร้างโฟลเดอร์สำหรับเก็บรูปภาพ
        capture_dir = os.path.join(current_dir, "captured_plates")
        os.makedirs(capture_dir, exist_ok=True)

        model = torch.hub.load('ultralytics/yolov5', 'custom', 
                             path=yolo_model_path, 
                             force_reload=True)
        
        model.conf = 0.7
        model.max_det = 2  # เพิ่มการตรวจจับหลายคลาส

        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise ValueError("ไม่สามารถเปิดกล้องได้")

        class_names = ["car", "licenseplate"]
        target_classes = [0, 1]  # 0 = car, 1 = licenseplate

        # กำหนด Trigger Zone
        trigger_zone = ((100, 100), (400, 400))  # พื้นที่ (xmin, ymin), (xmax, ymax)
        trigger_start_time = None
        last_ocr_time = 0  # บันทึกเวลาที่ทำ OCR ล่าสุด
        object_in_zone = False

        # เก็บผลลัพธ์ OCR
        ocr_results = []

        while True:
            ret, frame = cap.read()
            if not ret:
                print("ไม่สามารถอ่านภาพจากกล้องได้")
                break

            # วาด Trigger Zone ไว้ตลอดเวลา
            cv2.rectangle(frame, trigger_zone[0], trigger_zone[1], (255, 0, 0), 2)  # วาดกรอบสีน้ำเงิน

            results = model(frame)

            if len(results.xyxy[0]) > 0:
                for detection in results.xyxy[0]:  # ตรวจสอบการตรวจจับแต่ละรายการ
                    xmin, ymin, xmax, ymax, conf, cls = detection.cpu().numpy()
                    xmin, ymin, xmax, ymax = map(int, [xmin, ymin, xmax, ymax])

                    if int(cls) in target_classes:  # ตรวจจับ car หรือ licenseplate
                        cx, cy = (xmin + xmax) // 2, (ymin + ymax) // 2  # จุดศูนย์กลางของ Bounding Box

                        # วาดกรอบและเขียนข้อความ (ชื่อคลาส + Confidence)
                        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
                        label = f"{class_names[int(cls)]}: {conf:.2%}"
                        cv2.putText(frame, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                        # ตรวจสอบว่ารถหรือป้ายทะเบียนอยู่ใน Trigger Zone
                        if trigger_zone[0][0] < cx < trigger_zone[1][0] and trigger_zone[0][1] < cy < trigger_zone[1][1]:
                            if not object_in_zone:
                                object_in_zone = True
                                trigger_start_time = time.time()
                            elif time.time() - trigger_start_time >= 1:  # อยู่ในโซนเกิน 1 วินาที
                                current_time = time.time()
                                if current_time - last_ocr_time >= 2:  # เช็ก delay 2 วินาที
                                    print(f"{class_names[int(cls)]} detected in trigger zone for 1 second. Starting OCR process.")
                                    last_ocr_time = current_time  # บันทึกเวลาที่ OCR ล่าสุด

                                    # OCR Process
                                    plate_img = frame[ymin:ymax, xmin:xmax]
                                    plate_img = cv2.resize(plate_img, (224, 224))

                                    try:
                                        transformed_img = process_auto_transform(plate_img)
                                        top_img, _ = process_split_image(transformed_img)
                                        results, confidence = process_read_license(top_img, model_path, font_path)
                                        
                                        text = ''.join([char for char, _, _ in results])
                                        print(f"\nDetected: {text}")
                                        print(f"Confidence: {confidence:.2%}")

                                        # เก็บผลลัพธ์ OCR
                                        ocr_results.append((text, confidence))

                                        # แสดงผลลัพธ์ที่ดีที่สุด
                                        best_result = max(ocr_results, key=lambda x: x[1])  # เลือกผลลัพธ์ที่ confidence สูงสุด
                                        print(f"Best Detected: {best_result[0]} with Confidence: {best_result[1]:.2%}")

                                    except Exception as e:
                                        print(f"OCR Error: {str(e)}")
                        else:
                            object_in_zone = False  # รีเซ็ตสถานะหากออกจากโซน

            cv2.imshow('License Plate Detection', frame)

            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
                
    except Exception as e:
        print(f"\nเกิดข้อผิดพลาด: {str(e)}")
    finally:
        if 'cap' in locals():
            cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
